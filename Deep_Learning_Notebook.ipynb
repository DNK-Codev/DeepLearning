{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbFi2ei_qgzs"
      },
      "source": [
        "# ðŸ§  Deep Learning Layer-by-Layer Visualization with Keras\n",
        "This notebook demonstrates each common deep learning layer (Conv2D, ReLU, MaxPooling2D, Dense, and Softmax) using TensorFlow Keras API, including visualizations after each layer."
      ],
      "id": "LbFi2ei_qgzs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pYSHHz_qgzu"
      },
      "source": [
        "# Imports and Setup\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Create a sample input image (6x6 grayscale)\n",
        "image = np.array([\n",
        "    [1, 2, 1, 0, 0, 0],\n",
        "    [4, 5, 2, 0, 0, 0],\n",
        "    [1, 2, 1, 0, 0, 0],\n",
        "    [0, 1, 3, 2, 2, 0],\n",
        "    [0, 1, 4, 4, 4, 0],\n",
        "    [0, 1, 2, 3, 3, 0]\n",
        "], dtype=np.float32)\n",
        "\n",
        "# Reshape for TF model: (batch_size, height, width, channels)\n",
        "image_tf = image.reshape((1, 6, 6, 1))"
      ],
      "id": "0pYSHHz_qgzu",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUPkiYRSqgzv"
      },
      "source": [
        "# 1. Conv2D Layer\n",
        "conv_layer = layers.Conv2D(filters=1, kernel_size=3, strides=1, padding='valid', use_bias=False)\n",
        "model_conv = models.Sequential([conv_layer])\n",
        "conv_output = model_conv(image_tf)\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Conv2D Output\")\n",
        "plt.imshow(conv_output[0, :, :, 0], cmap='gray')\n",
        "plt.show()"
      ],
      "id": "JUPkiYRSqgzv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qylj8epqgzw"
      },
      "source": [
        "# 2. ReLU Activation Layer\n",
        "relu_layer = layers.ReLU()\n",
        "model_relu = models.Sequential([conv_layer, relu_layer])\n",
        "relu_output = model_relu(image_tf)\n",
        "\n",
        "plt.title(\"ReLU Output\")\n",
        "plt.imshow(relu_output[0, :, :, 0], cmap='gray')\n",
        "plt.show()"
      ],
      "id": "0qylj8epqgzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPgUO27iqgzw"
      },
      "source": [
        "# 3. MaxPooling2D Layer\n",
        "pool_layer = layers.MaxPooling2D(pool_size=(2, 2), strides=2)\n",
        "model_pool = models.Sequential([conv_layer, relu_layer, pool_layer])\n",
        "pool_output = model_pool(image_tf)\n",
        "\n",
        "plt.title(\"Max Pooling Output\")\n",
        "plt.imshow(pool_output[0, :, :, 0], cmap='gray')\n",
        "plt.show()"
      ],
      "id": "lPgUO27iqgzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymKTJLWrqgzw"
      },
      "source": [
        "# 4. Fully Connected Layer\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer = layers.Dense(units=3)  # 3 classes\n",
        "model_fc = models.Sequential([conv_layer, relu_layer, pool_layer, flatten_layer, dense_layer])\n",
        "fc_output = model_fc(image_tf)\n",
        "\n",
        "print(\"Fully Connected Output:\", fc_output.numpy())"
      ],
      "id": "ymKTJLWrqgzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV0G_FRRqgzw"
      },
      "source": [
        "# 5. Softmax Layer\n",
        "softmax_layer = layers.Softmax()\n",
        "model_softmax = models.Sequential([\n",
        "    conv_layer, relu_layer, pool_layer,\n",
        "    flatten_layer, dense_layer, softmax_layer\n",
        "])\n",
        "softmax_output = model_softmax(image_tf)\n",
        "\n",
        "print(\"Softmax Probabilities:\", softmax_output.numpy())\n",
        "\n",
        "# Visualize class probabilities\n",
        "plt.bar(range(3), softmax_output.numpy()[0])\n",
        "plt.title(\"Softmax Output\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()"
      ],
      "id": "LV0G_FRRqgzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Classification"
      ],
      "metadata": {
        "id": "o-xJmCEsXfXl"
      },
      "id": "o-xJmCEsXfXl"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "# Normalize images to the range [0,1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add channel dimension (batch, height, width, channel)\n",
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# 2. Build CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 3. Train model\n",
        "history = model.fit(x_train, y_train_cat, epochs=5,\n",
        "                    validation_split=0.1, batch_size=64)\n",
        "\n",
        "# 4. Evaluate model on test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# 5. Run inference on sample test images\n",
        "pred_probs = model.predict(x_test[:10])\n",
        "pred_classes = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# 6. Visualize predictions\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(x_test[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Pred: {pred_classes[i]}\\nTrue: {y_test[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training History')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Xl1HvOxCXT0l"
      },
      "id": "Xl1HvOxCXT0l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IRIS Classification"
      ],
      "metadata": {
        "id": "xAjqV6hIXZ9s"
      },
      "id": "xAjqV6hIXZ9s"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn matplotlib seaborn\n"
      ],
      "metadata": {
        "id": "Mxrl_YAlXlxX"
      },
      "id": "Mxrl_YAlXlxX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load and preprocess the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "class_names = iris.target_names\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# One-hot encode target\n",
        "y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "y_test_cat = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# 2. Build the MLP model\n",
        "model = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(4,)),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 3. Train the model\n",
        "history = model.fit(X_train, y_train_cat,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=50,\n",
        "                    batch_size=8,\n",
        "                    verbose=1)\n",
        "\n",
        "# 4. Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat)\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predict\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# 5. Visualization - Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 6. Visualization - Feature Scatter Plot (First 2 features)\n",
        "plt.figure(figsize=(8, 5))\n",
        "for i in range(3):\n",
        "    idx = np.where(y_test == i)\n",
        "    plt.scatter(X_test[idx, 0], X_test[idx, 1], label=class_names[i], edgecolors='k')\n",
        "plt.title(\"Iris Test Data (First 2 Features)\")\n",
        "plt.xlabel(\"Sepal Length (standardized)\")\n",
        "plt.ylabel(\"Sepal Width (standardized)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1HmI2YeqXdhf"
      },
      "id": "1HmI2YeqXdhf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}